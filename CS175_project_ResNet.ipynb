{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Testing: Resnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SabtheCrab/CS-175-Final-Project/blob/master/CS175_project_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "l_nrgUrT8iZg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **CS 175 Final Project: Humback Whale Identification**\n",
        "\n",
        "**Group Member 1:**\n",
        "\n",
        "Name: Sabrina Will\n",
        "\n",
        "**Group Member 2:**\n",
        "\n",
        "Name: Jeffrey Lee Ye\n",
        "\n",
        "CREDITS FOR BOUNDING BOX CROPPED DATASET: https://www.kaggle.com/josemontiel/humpback-whale-bounding-box-cropped-dataset/output"
      ]
    },
    {
      "metadata": {
        "id": "P5-Q0cWf6LFZ",
        "colab_type": "code",
        "outputId": "2681e60c-6267-4002-f1df-3b64e0a8ae27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#We are using a data set, which originally came from the kaggle competition. However, many of the images suffered from misalignment issues and have \n",
        "#large amounts of background space we dont need our AI to consider when looking at whale flukes. As such, someone blessed competitors with a\n",
        "#dataset that reformats all original images and crops out just the whale fluke itself. This is the data we are using in our project. \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PTa8bvn1Zief",
        "colab_type": "code",
        "outputId": "f56ecd1b-39b5-4c3f-eccf-d3f2e33295ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My\\ Drive/CS\\ 175\\ Final\\ Project/data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CS 175 Final Project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aFzT8oQ3_EzC",
        "colab_type": "code",
        "outputId": "83e24498-09de-497a-d64c-82f8de717e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "import copy, cv2, json, os, time, torch, torchvision\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "testDf = pd.read_csv('sample_submission.csv')\n",
        "print(df.head())\n",
        "print(testDf.head())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Image         Id\n",
            "0  0000e88ab.jpg  w_f48451c\n",
            "1  0001f9222.jpg  w_c3d896a\n",
            "2  00029d126.jpg  w_20df2c5\n",
            "3  00050a15a.jpg  new_whale\n",
            "4  0005c1ef8.jpg  new_whale\n",
            "           Image                                                 Id\n",
            "0  00028a005.jpg  new_whale w_23a388d w_9b5109b w_9c506f6 w_0369a5c\n",
            "1  000dcf7d8.jpg  new_whale w_23a388d w_9b5109b w_9c506f6 w_0369a5c\n",
            "2  000e7c7df.jpg  new_whale w_23a388d w_9b5109b w_9c506f6 w_0369a5c\n",
            "3  0019c34f4.jpg  new_whale w_23a388d w_9b5109b w_9c506f6 w_0369a5c\n",
            "4  001a4d292.jpg  new_whale w_23a388d w_9b5109b w_9c506f6 w_0369a5c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DgyLbBoLPkHf",
        "colab_type": "code",
        "outputId": "f62ad452-b5fb-4783-8a6b-b90ef2ea658c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "print(testDf.columns)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Image', 'Id'], dtype='object')\n",
            "Index(['Image', 'Id'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kgo6YBO_ZV2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#credit to: https://github.com/AdityaSidharta/kaggle_humpback_whale/blob/master/humpback_whale.ipynb for plot_images function\n",
        "def plot_images(filenames, table_size, labels = '', traintest = 'train'):\n",
        "    imgs_filename = [traintest + '/' + str(filename) for filename in filenames]\n",
        "    imgs = [plt.imread(filename) for filename in imgs_filename]\n",
        "    figure = plt.figure(figsize=(20, 10))\n",
        "    rows, cols = table_size\n",
        "    for i in range(len(imgs)):\n",
        "        subplot = figure.add_subplot(rows, cols, i + 1)\n",
        "        subplot.axis('Off')\n",
        "        if not np.all(labels == ''):\n",
        "            subplot.set_title(labels[i], fontsize=10)\n",
        "        subplot.imshow(imgs[i], cmap='gray')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N6Olt6MRzs-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d163d528-6b16-4a4b-f80c-75c2bf55882e"
      },
      "cell_type": "code",
      "source": [
        "#showing random whale images to make sure i loaded in the data properly\n",
        "%cd /content/drive/My\\ Drive/CS\\ 175\\ Final\\ Project/data/train/output/humpback-whale-identification-cropped/\n",
        "\n",
        "# plot_images(df.Image[:20], (5,4) ,df.Id[:20], 'train')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CS 175 Final Project/data/train/output/humpback-whale-identification-cropped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ujvcCTdqQD9q",
        "colab_type": "code",
        "outputId": "b5ed7c7c-5292-4d28-e2ad-259b70443ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My\\ Drive/CS\\ 175\\ Final\\ Project/data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CS 175 Final Project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "11zdh7XSixXW",
        "colab_type": "code",
        "outputId": "cbeb6764-f8c8-4877-885b-5d51f7752358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#find number of unique whale individuals\n",
        "\n",
        "n_unique = len(df['Id'].unique())\n",
        "print (\"Number of Unique Categories : \" + str(n_unique))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Unique Categories : 5005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cbtSMiejh_eq",
        "colab_type": "code",
        "outputId": "7465ea0c-09c8-4035-a5b9-2d7f217dce96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "n_train = len(df['Id'])\n",
        "#counts of each unique whale\n",
        "weight_series = df['Id'].value_counts()\n",
        "weight_df = pd.DataFrame(weight_series)\n",
        "weight_df.columns = ['count']\n",
        "weight_df['count'] = weight_df['count'].astype(float)\n",
        "weight_df['Id'] = weight_df.index\n",
        "weight_df = weight_df.reset_index(drop = True)\n",
        "# weight_df['weight'] = n_train / (n_unique * weight_df['count'] )\n",
        "\n",
        "label_to_idNum = dict(zip(weight_df['Id'], range(n_unique)))\n",
        "weight_df"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9664.0</td>\n",
              "      <td>new_whale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>73.0</td>\n",
              "      <td>w_23a388d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>w_9b5109b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62.0</td>\n",
              "      <td>w_9c506f6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61.0</td>\n",
              "      <td>w_0369a5c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>57.0</td>\n",
              "      <td>w_700ebb4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>54.0</td>\n",
              "      <td>w_3de579a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>51.0</td>\n",
              "      <td>w_564a34b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>50.0</td>\n",
              "      <td>w_fd3e556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>49.0</td>\n",
              "      <td>w_88e4537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>48.0</td>\n",
              "      <td>w_2b069ba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>47.0</td>\n",
              "      <td>w_d405854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>45.0</td>\n",
              "      <td>w_789c969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>45.0</td>\n",
              "      <td>w_f0fe284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>40.0</td>\n",
              "      <td>w_5e8e218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>40.0</td>\n",
              "      <td>w_778e474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>40.0</td>\n",
              "      <td>w_343f088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>37.0</td>\n",
              "      <td>w_5a2634c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>37.0</td>\n",
              "      <td>w_60ce6fc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>37.0</td>\n",
              "      <td>w_a9304b9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>36.0</td>\n",
              "      <td>w_6822dbc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>35.0</td>\n",
              "      <td>w_af367c3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>34.0</td>\n",
              "      <td>w_1ca9ab1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>34.0</td>\n",
              "      <td>w_f765256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>33.0</td>\n",
              "      <td>w_17b0d3a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>32.0</td>\n",
              "      <td>w_d72771c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>31.0</td>\n",
              "      <td>w_08630fd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>31.0</td>\n",
              "      <td>w_6cda039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>31.0</td>\n",
              "      <td>w_8c25681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30.0</td>\n",
              "      <td>w_51fc1fc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_05fbf14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4976</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_e63ea91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4977</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_628d615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4978</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_c68b887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4979</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_e8aa833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4980</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_ed1c5c2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4981</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_efaba3b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4982</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_ed07656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4983</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_925bdf6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4984</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_fea5f70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4985</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_44fe688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4986</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_81b2e1e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4987</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_6eed962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4988</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_378bf61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4989</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_ec63b66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4990</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_62ff333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_9ac40d5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_ee76222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_203042e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_a3e2d0f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_eae91de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_887c387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_cd1905a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_c640984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_fb0c41f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5000</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_da04408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5001</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_3ef0017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5002</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_64062df</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5003</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_6d8519e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5004</th>\n",
              "      <td>1.0</td>\n",
              "      <td>w_46a38a6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5005 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       count         Id\n",
              "0     9664.0  new_whale\n",
              "1       73.0  w_23a388d\n",
              "2       65.0  w_9b5109b\n",
              "3       62.0  w_9c506f6\n",
              "4       61.0  w_0369a5c\n",
              "5       57.0  w_700ebb4\n",
              "6       54.0  w_3de579a\n",
              "7       51.0  w_564a34b\n",
              "8       50.0  w_fd3e556\n",
              "9       49.0  w_88e4537\n",
              "10      48.0  w_2b069ba\n",
              "11      47.0  w_d405854\n",
              "12      45.0  w_789c969\n",
              "13      45.0  w_f0fe284\n",
              "14      40.0  w_5e8e218\n",
              "15      40.0  w_778e474\n",
              "16      40.0  w_343f088\n",
              "17      37.0  w_5a2634c\n",
              "18      37.0  w_60ce6fc\n",
              "19      37.0  w_a9304b9\n",
              "20      36.0  w_6822dbc\n",
              "21      35.0  w_af367c3\n",
              "22      34.0  w_1ca9ab1\n",
              "23      34.0  w_f765256\n",
              "24      33.0  w_17b0d3a\n",
              "25      32.0  w_d72771c\n",
              "26      31.0  w_08630fd\n",
              "27      31.0  w_6cda039\n",
              "28      31.0  w_8c25681\n",
              "29      30.0  w_51fc1fc\n",
              "...      ...        ...\n",
              "4975     1.0  w_05fbf14\n",
              "4976     1.0  w_e63ea91\n",
              "4977     1.0  w_628d615\n",
              "4978     1.0  w_c68b887\n",
              "4979     1.0  w_e8aa833\n",
              "4980     1.0  w_ed1c5c2\n",
              "4981     1.0  w_efaba3b\n",
              "4982     1.0  w_ed07656\n",
              "4983     1.0  w_925bdf6\n",
              "4984     1.0  w_fea5f70\n",
              "4985     1.0  w_44fe688\n",
              "4986     1.0  w_81b2e1e\n",
              "4987     1.0  w_6eed962\n",
              "4988     1.0  w_378bf61\n",
              "4989     1.0  w_ec63b66\n",
              "4990     1.0  w_62ff333\n",
              "4991     1.0  w_9ac40d5\n",
              "4992     1.0  w_ee76222\n",
              "4993     1.0  w_203042e\n",
              "4994     1.0  w_a3e2d0f\n",
              "4995     1.0  w_eae91de\n",
              "4996     1.0  w_887c387\n",
              "4997     1.0  w_cd1905a\n",
              "4998     1.0  w_c640984\n",
              "4999     1.0  w_fb0c41f\n",
              "5000     1.0  w_da04408\n",
              "5001     1.0  w_3ef0017\n",
              "5002     1.0  w_64062df\n",
              "5003     1.0  w_6d8519e\n",
              "5004     1.0  w_46a38a6\n",
              "\n",
              "[5005 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "NjkulbM61-rv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Most classes only have a few to one image within them"
      ]
    },
    {
      "metadata": {
        "id": "GS9OR6clz8B1",
        "colab_type": "code",
        "outputId": "43b38435-6a72-41dd-daaa-056bae4a8aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "total = len(df['Id'])\n",
        "print(f'Total images in training set {total}')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total images in training set 25361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pOYSHfwPXykx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HumpbackWhale_Dataset(Dataset):\n",
        "    def __init__(self,filepath, csv_path, transform=None):\n",
        "        self.file_path = filepath\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.transform = transform\n",
        "        self.image_list = [x for x in os.listdir(self.file_path)]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return(len(self.image_list))\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        img_path = os.path.join(self.file_path,self.image_list[idx])\n",
        "        label = self.df.Id[idx]\n",
        "        imgRGB = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(imgRGB)\n",
        "        imgName = self.image_list[idx]\n",
        "        return img, label, imgName\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5fE6mUnYFQWJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def label_to_id(label):\n",
        "    x = [label_to_idNum[i] for i in label]\n",
        "    return torch.tensor(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IKP3zlsfWOGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dims = 128\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                              transforms.Resize((dims, dims)),\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                     std=[0.229, 0.224, 0.225])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBOsLccLZNSh",
        "colab_type": "code",
        "outputId": "a3837176-ab4d-4e73-fb90-3a7277fabf25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# This may give errors for a while because all the images are still being loaded in the directory\n",
        "# Just wait and keep running this until this cell works\n",
        "%cd /content/drive/My\\ Drive/CS\\ 175\\ Final\\ Project/data\n",
        "train_dataset = HumpbackWhale_Dataset('train/output/humpback-whale-identification-cropped/train','train.csv', transform)\n",
        "test_dataset = HumpbackWhale_Dataset('test/output/humpback-whale-identification-cropped/test','sample_submission.csv', transform)\n",
        "print(len(train_dataset.image_list))\n",
        "print(len(test_dataset.image_list))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CS 175 Final Project/data\n",
            "25361\n",
            "7960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i1-Ltc6dL22a",
        "colab_type": "code",
        "outputId": "6dea6f2a-1cb1-478f-c891-78402feb77e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].size()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 128, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "DGcNlcnJNo-s",
        "colab_type": "code",
        "outputId": "2d69b9b6-bb01-43e0-ce7c-7e5b7ead465c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "test_size = .2\n",
        "n = len(train_dataset)\n",
        "\n",
        "np.random.seed(0)\n",
        "a = list(range(n))\n",
        "\n",
        "train_index = np.random.choice(a,replace=False,size=int(n*(1-test_size)))\n",
        "test_index = np.setdiff1d(a,train_index)\n",
        "print(train_index.size)\n",
        "print(test_index.size)\n",
        "\n",
        "\n",
        "use_only = 0.1\n",
        "train_cut_index = np.random.choice(train_index, replace=False, size=int(train_index.size * use_only))\n",
        "test_cut_index = np.random.choice(test_index, replace=False, size=int(test_index.size * use_only))\n",
        "print(\"cut size:\")\n",
        "print(train_cut_index.size)\n",
        "print(test_cut_index.size)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20288\n",
            "5073\n",
            "cut size:\n",
            "2028\n",
            "507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o2zc4YhdkFO8",
        "colab_type": "code",
        "outputId": "1e766839-bce2-4e59-cc2b-34757ab76ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "data_train = copy.deepcopy(train_dataset)\n",
        "data_train.image_list = [train_dataset.image_list[i] for i in train_cut_index]\n",
        "\n",
        "data_test = copy.deepcopy(train_dataset)\n",
        "data_test.image_list = [train_dataset.image_list[i] for i in test_cut_index]\n",
        "\n",
        "gen_train = DataLoader(data_train,batch_size=100, shuffle=True)\n",
        "gen_test = DataLoader(data_test,batch_size=100, shuffle=True)\n",
        "full_train_generator = DataLoader(train_dataset,batch_size=100, shuffle=True)\n",
        "full_test_generator = DataLoader(test_dataset,batch_size=100, shuffle=True)\n",
        "\n",
        "print(len(gen_train))\n",
        "print(len(gen_test))\n",
        "print(len(full_train_generator))\n",
        "print(len(full_test_generator))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21\n",
            "6\n",
            "254\n",
            "80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5koUMkKoq3Qk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RahJXECqkUEG",
        "colab_type": "code",
        "outputId": "eb897355-509e-4d78-a551-6ce5caef95e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=5005):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(int(32*dims*dims/4/4), num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "print(\"Cuda\" if torch.cuda.is_available() else \"CPU\")\n",
        "  \n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device('cpu')\n",
        "\n",
        "model = ConvNet(n_unique).to(device)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7bFjGBlYpXBD",
        "colab_type": "code",
        "outputId": "54daf81a-286b-4bb3-f1a7-dd0e8f3b978a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        }
      },
      "cell_type": "code",
      "source": [
        "# ResNet \n",
        "model = models.resnet18(num_classes=5005).to(device)\n",
        "print(model)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=5005, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2-uJ7obFZ4uH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zBQ5PqwIGhY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load already created model\n",
        "checkpoint = torch.load('checkpoint2.pth.tar')\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# can skip training if this node is run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qZfUR-9K6VG8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def testModel(model, testing_data, debug_log = False):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      numCorrect = 0\n",
        "      total = 0\n",
        "      batch = 0 \n",
        "      progress_printer = 15\n",
        "      for image, label, _ in testing_data:\n",
        "          label = label_to_id(label).to(device)\n",
        "          image = image.to(device)\n",
        "          predicted = model(image)\n",
        "          top5Pred, top5PredIndices = torch.topk(predicted, 5) \n",
        "          # gives something of size (batchsize x 5)\n",
        "          #top5Pred, top5PredIndices = torch.topk(predicted, 1)\n",
        "          for p in range(len(top5PredIndices)):\n",
        "              currPred = top5PredIndices[p]\n",
        "              if (batch % progress_printer == 0 and debug_log):\n",
        "                print(f'{label[p]} is in {currPred}')\n",
        "              numCorrect += 1 if (label[p] in currPred) else 0\n",
        "          total += len(label)\n",
        "          if (batch % progress_printer == 0 and debug_log):\n",
        "            print(\"NumCorrect:\", numCorrect, \"with total:\", total, \" (Batch\", batch, \")\")\n",
        "          batch += 1\n",
        "      return numCorrect / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1YVAOlkk-zD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainModel(model, criterion, optimizer, epochs=8):\n",
        "  # Train data on part of the full training data to check performance with\n",
        "  training_data = gen_train\n",
        "\n",
        "  image_count = len(training_data)\n",
        "  progress_printer = 3\n",
        "\n",
        "  train_acc_list = []\n",
        "  val_acc_list = []\n",
        "\n",
        "  for e in range(epochs):\n",
        "      running_loss, i = 0, 0\n",
        "\n",
        "      for image, label, _ in training_data:\n",
        "          label = label_to_id(label)\n",
        "          image, label = image.to(device), label.to(device)\n",
        "          i +=1 \n",
        "          if i % progress_printer == 0:\n",
        "              print('{:.0f}% complete'.format(i/image_count*100))\n",
        "          log_ps = model(image)\n",
        "          loss = criterion(log_ps, label)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          if (e == 0 and running_loss == 0):\n",
        "              print('First data passed')\n",
        "\n",
        "          running_loss += loss.item()\n",
        "      train_acc_list.append(testModel(model, gen_train))\n",
        "      val_acc_list.append(testModel(model, gen_test))\n",
        "\n",
        "      print('epoch {}, loss: {}, train_acc: {}, val_acc: {}'.format(e, running_loss, train_acc_list[-1], val_acc_list[-1]))\n",
        "  return train_acc_list, val_acc_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-L9N3xrLYDQm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ResNet18 - 8 epochs, 100 batch size, 1e-3 learning rate\n",
        "print('Train acc list:', train_acc_list)\n",
        "print('Val   acc list:', val_acc_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "treEJcCJT4n0",
        "colab_type": "code",
        "outputId": "c48e284b-ea33-4a7f-a5ed-629047c21ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3349
        }
      },
      "cell_type": "code",
      "source": [
        "# ResNet18 - 6 epochs, 100 batch size, various learning rates\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learn_rates = [1.5e-2, 7.5e-3, 1e-3, 2.5e-4]\n",
        "all_train_acc_rn18 = []\n",
        "all_val_acc_rn18 = []\n",
        "models_rn18 = []\n",
        "\n",
        "for lr in learn_rates:\n",
        "  model = models.resnet18(num_classes=5005).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  train_acc, val_acc = trainModel(model, criterion, optimizer, epochs=6)\n",
        "  all_train_acc_rn18.append(train_acc)\n",
        "  all_val_acc_rn18.append(val_acc)\n",
        "  models_rn18.append(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First data passed\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 0, loss: 170.48262739181519, train_acc: 0.40828402366863903, val_acc: 0.39447731755424065\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 1, loss: 119.25123500823975, train_acc: 0.41025641025641024, val_acc: 0.39644970414201186\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 2, loss: 104.63168621063232, train_acc: 0.4156804733727811, val_acc: 0.40828402366863903\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 3, loss: 103.14034080505371, train_acc: 0.4161735700197239, val_acc: 0.40433925049309666\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 4, loss: 100.90903186798096, train_acc: 0.4176528599605523, val_acc: 0.40433925049309666\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 5, loss: 98.11774444580078, train_acc: 0.4156804733727811, val_acc: 0.40433925049309666\n",
            "First data passed\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 0, loss: 150.29216051101685, train_acc: 0.40581854043392507, val_acc: 0.39447731755424065\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 1, loss: 185.2890429496765, train_acc: 0.41222879684418146, val_acc: 0.40039447731755423\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 2, loss: 103.78850412368774, train_acc: 0.41420118343195267, val_acc: 0.40631163708086787\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 3, loss: 102.92565155029297, train_acc: 0.41420118343195267, val_acc: 0.40631163708086787\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 4, loss: 101.73435163497925, train_acc: 0.4156804733727811, val_acc: 0.40236686390532544\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 5, loss: 101.7653579711914, train_acc: 0.41469428007889547, val_acc: 0.40433925049309666\n",
            "First data passed\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 0, loss: 138.19521760940552, train_acc: 0.29930966469428005, val_acc: 0.2958579881656805\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 1, loss: 109.01110601425171, train_acc: 0.41222879684418146, val_acc: 0.40236686390532544\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 2, loss: 103.1985855102539, train_acc: 0.4151873767258383, val_acc: 0.40433925049309666\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 3, loss: 100.70898580551147, train_acc: 0.41469428007889547, val_acc: 0.40236686390532544\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 4, loss: 99.89494895935059, train_acc: 0.4171597633136095, val_acc: 0.40236686390532544\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 5, loss: 98.25378799438477, train_acc: 0.41913214990138065, val_acc: 0.40433925049309666\n",
            "First data passed\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 0, loss: 144.36530303955078, train_acc: 0.41124260355029585, val_acc: 0.398422090729783\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 1, loss: 107.46703767776489, train_acc: 0.4176528599605523, val_acc: 0.40433925049309666\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 2, loss: 102.079843044281, train_acc: 0.41863905325443784, val_acc: 0.40039447731755423\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 3, loss: 101.3148717880249, train_acc: 0.4235700197238659, val_acc: 0.40433925049309666\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 4, loss: 98.80071353912354, train_acc: 0.4285009861932939, val_acc: 0.41025641025641024\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 5, loss: 95.76071047782898, train_acc: 0.4393491124260355, val_acc: 0.41420118343195267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tHtkiDH1YcPm",
        "colab_type": "code",
        "outputId": "8e97b569-3c91-4525-d8e4-e30068534b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2618
        }
      },
      "cell_type": "code",
      "source": [
        "# ResNet50 - 6 epochs, 100 batch size, various learning rates\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learn_rates = [7.8e-2, 1e-2, 1e-3]\n",
        "all_train_acc_rn50 = []\n",
        "all_val_acc_rn50 = []\n",
        "models_rn50 = []\n",
        "\n",
        "for lr in learn_rates:\n",
        "  print('learning rate:', lr)\n",
        "  model = models.resnet18(num_classes=5005).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  train_acc, val_acc = trainModel(model, criterion, optimizer, epochs=6)\n",
        "  all_train_acc_rn18.append(train_acc)\n",
        "  all_val_acc_rn18.append(val_acc)\n",
        "  models_rn50.append(model)\n",
        "  print(' ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate: 0.078\n",
            "First data passed\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 0, loss: 296.4185080528259, train_acc: 0.03106508875739645, val_acc: 0.015779092702169626\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 1, loss: 2066.790955066681, train_acc: 0.41272189349112426, val_acc: 0.40828402366863903\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 2, loss: 105.9506425857544, train_acc: 0.41469428007889547, val_acc: 0.40828402366863903\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 3, loss: 102.87263631820679, train_acc: 0.4151873767258383, val_acc: 0.40828402366863903\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 4, loss: 101.48332500457764, train_acc: 0.4151873767258383, val_acc: 0.40631163708086787\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 5, loss: 100.49616765975952, train_acc: 0.41469428007889547, val_acc: 0.40631163708086787\n",
            " \n",
            "learning rate: 0.01\n",
            "First data passed\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 0, loss: 154.68528604507446, train_acc: 0.40828402366863903, val_acc: 0.39447731755424065\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 1, loss: 1139.9141721725464, train_acc: 0.41074950690335305, val_acc: 0.398422090729783\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 2, loss: 106.48848104476929, train_acc: 0.41272189349112426, val_acc: 0.40433925049309666\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 3, loss: 104.03956079483032, train_acc: 0.41272189349112426, val_acc: 0.40631163708086787\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 4, loss: 102.79808759689331, train_acc: 0.41469428007889547, val_acc: 0.40236686390532544\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 5, loss: 103.11719846725464, train_acc: 0.41420118343195267, val_acc: 0.40236686390532544\n",
            " \n",
            "learning rate: 0.001\n",
            "First data passed\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 0, loss: 138.88780975341797, train_acc: 0.29240631163708086, val_acc: 0.3136094674556213\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 1, loss: 111.52603006362915, train_acc: 0.41321499013806706, val_acc: 0.40236686390532544\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 2, loss: 102.59184217453003, train_acc: 0.41370808678500987, val_acc: 0.40631163708086787\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 3, loss: 99.94837498664856, train_acc: 0.4181459566074951, val_acc: 0.40433925049309666\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 4, loss: 99.79168510437012, train_acc: 0.41962524654832345, val_acc: 0.398422090729783\n",
            "14% complete\n",
            "29% complete\n",
            "43% complete\n",
            "57% complete\n",
            "71% complete\n",
            "86% complete\n",
            "100% complete\n",
            "epoch 5, loss: 96.99044251441956, train_acc: 0.4230769230769231, val_acc: 0.40433925049309666\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e8y-LnbVbGQL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainModel(model, criterion, optimizer, train_set, epochs=6):\n",
        "  # Train data on part of the full training data to check performance with\n",
        "  training_data = train_set\n",
        "\n",
        "  image_count = len(training_data)\n",
        "  progress_printer = int(image_count / 30)\n",
        "  print('Printing progress at every:', progress_printer)\n",
        "  \n",
        "  train_acc_list = []\n",
        "  val_acc_list = []\n",
        "\n",
        "  for e in range(epochs):\n",
        "      running_loss, i = 0, 0\n",
        "\n",
        "      for image, label, _ in training_data:\n",
        "          label = label_to_id(label)\n",
        "          image, label = image.to(device), label.to(device)\n",
        "          i +=1 \n",
        "          if i % progress_printer == 0:\n",
        "              print('{:.0f}% complete'.format(i/image_count*100))\n",
        "          log_ps = model(image)\n",
        "          loss = criterion(log_ps, label)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          if (e == 0 and running_loss == 0):\n",
        "              print('First data passed')\n",
        "\n",
        "          running_loss += loss.item()\n",
        "      train_acc_list.append(testModel(model, gen_train))\n",
        "      val_acc_list.append(testModel(model, gen_test))\n",
        "\n",
        "      print('epoch {}, loss: {}, train_acc: {}, val_acc: {}'.format(e, running_loss, train_acc_list[-1], val_acc_list[-1]))\n",
        "  return train_acc_list, val_acc_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tEIWwJhAZl2L",
        "colab_type": "code",
        "outputId": "b6698511-dbd0-4133-8b67-15af666964ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3298
        }
      },
      "cell_type": "code",
      "source": [
        "final_model = models.resnet50(num_classes=5005).to(device)\n",
        "final_criterion = nn.CrossEntropyLoss()\n",
        "final_optimizer = torch.optim.Adam(final_model.parameters(), lr=5e-2) \n",
        "\n",
        "final_train_acc, final_val_acc = trainModel(final_model, final_criterion, final_optimizer, full_train_generator)\n",
        "torch.save({'state_dict': final_model.state_dict()}, 'checkpoint_rn50.pth.tar')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing progress at every: 8\n",
            "First data passed\n",
            "3% complete\n",
            "6% complete\n",
            "9% complete\n",
            "13% complete\n",
            "16% complete\n",
            "19% complete\n",
            "22% complete\n",
            "25% complete\n",
            "28% complete\n",
            "31% complete\n",
            "35% complete\n",
            "38% complete\n",
            "41% complete\n",
            "44% complete\n",
            "47% complete\n",
            "50% complete\n",
            "54% complete\n",
            "57% complete\n",
            "60% complete\n",
            "63% complete\n",
            "66% complete\n",
            "69% complete\n",
            "72% complete\n",
            "76% complete\n",
            "79% complete\n",
            "82% complete\n",
            "85% complete\n",
            "88% complete\n",
            "91% complete\n",
            "94% complete\n",
            "98% complete\n",
            "epoch 0, loss: 1970.0830817222595, train_acc: 0.4068047337278107, val_acc: 0.39644970414201186\n",
            "3% complete\n",
            "6% complete\n",
            "9% complete\n",
            "13% complete\n",
            "16% complete\n",
            "19% complete\n",
            "22% complete\n",
            "25% complete\n",
            "28% complete\n",
            "31% complete\n",
            "35% complete\n",
            "38% complete\n",
            "41% complete\n",
            "44% complete\n",
            "47% complete\n",
            "50% complete\n",
            "54% complete\n",
            "57% complete\n",
            "60% complete\n",
            "63% complete\n",
            "66% complete\n",
            "69% complete\n",
            "72% complete\n",
            "76% complete\n",
            "79% complete\n",
            "82% complete\n",
            "85% complete\n",
            "88% complete\n",
            "91% complete\n",
            "94% complete\n",
            "98% complete\n",
            "epoch 1, loss: 1458.2029957771301, train_acc: 0.41173570019723865, val_acc: 0.40631163708086787\n",
            "3% complete\n",
            "6% complete\n",
            "9% complete\n",
            "13% complete\n",
            "16% complete\n",
            "19% complete\n",
            "22% complete\n",
            "25% complete\n",
            "28% complete\n",
            "31% complete\n",
            "35% complete\n",
            "38% complete\n",
            "41% complete\n",
            "44% complete\n",
            "47% complete\n",
            "50% complete\n",
            "54% complete\n",
            "57% complete\n",
            "60% complete\n",
            "63% complete\n",
            "66% complete\n",
            "69% complete\n",
            "72% complete\n",
            "76% complete\n",
            "79% complete\n",
            "82% complete\n",
            "85% complete\n",
            "88% complete\n",
            "91% complete\n",
            "94% complete\n",
            "98% complete\n",
            "epoch 2, loss: 1451.6767473220825, train_acc: 0.41124260355029585, val_acc: 0.40236686390532544\n",
            "3% complete\n",
            "6% complete\n",
            "9% complete\n",
            "13% complete\n",
            "16% complete\n",
            "19% complete\n",
            "22% complete\n",
            "25% complete\n",
            "28% complete\n",
            "31% complete\n",
            "35% complete\n",
            "38% complete\n",
            "41% complete\n",
            "44% complete\n",
            "47% complete\n",
            "50% complete\n",
            "54% complete\n",
            "57% complete\n",
            "60% complete\n",
            "63% complete\n",
            "66% complete\n",
            "69% complete\n",
            "72% complete\n",
            "76% complete\n",
            "79% complete\n",
            "82% complete\n",
            "85% complete\n",
            "88% complete\n",
            "91% complete\n",
            "94% complete\n",
            "98% complete\n",
            "epoch 3, loss: 1450.7361364364624, train_acc: 0.41321499013806706, val_acc: 0.40433925049309666\n",
            "3% complete\n",
            "6% complete\n",
            "9% complete\n",
            "13% complete\n",
            "16% complete\n",
            "19% complete\n",
            "22% complete\n",
            "25% complete\n",
            "28% complete\n",
            "31% complete\n",
            "35% complete\n",
            "38% complete\n",
            "41% complete\n",
            "44% complete\n",
            "47% complete\n",
            "50% complete\n",
            "54% complete\n",
            "57% complete\n",
            "60% complete\n",
            "63% complete\n",
            "66% complete\n",
            "69% complete\n",
            "72% complete\n",
            "76% complete\n",
            "79% complete\n",
            "82% complete\n",
            "85% complete\n",
            "88% complete\n",
            "91% complete\n",
            "94% complete\n",
            "98% complete\n",
            "3% complete\n",
            "6% complete\n",
            "9% complete\n",
            "13% complete\n",
            "16% complete\n",
            "19% complete\n",
            "22% complete\n",
            "25% complete\n",
            "28% complete\n",
            "31% complete\n",
            "35% complete\n",
            "38% complete\n",
            "41% complete\n",
            "44% complete\n",
            "47% complete\n",
            "50% complete\n",
            "54% complete\n",
            "57% complete\n",
            "60% complete\n",
            "63% complete\n",
            "66% complete\n",
            "69% complete\n",
            "72% complete\n",
            "76% complete\n",
            "79% complete\n",
            "82% complete\n",
            "85% complete\n",
            "88% complete\n",
            "91% complete\n",
            "94% complete\n",
            "98% complete\n",
            "epoch 5, loss: 1450.3411183357239, train_acc: 0.41222879684418146, val_acc: 0.398422090729783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pKD5iYIVdBaz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_gwrRFEK7euT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Using loaded model\n",
        "loaded_model = ConvNet(n_unique).to(device)\n",
        "# Load already created model\n",
        "checkpoint = torch.load('checkpoint2.pth.tar')\n",
        "loaded_model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "# can skip training if this node is run\n",
        "\n",
        "print(len(gen_train))\n",
        "training_acc = testModel(loaded_model, gen_train)\n",
        "print('Training acc:', training_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "by2M9U2Yqguu",
        "colab_type": "code",
        "outputId": "e1a9c50e-813f-43b5-8f9b-faa6805c6e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(epoch,loss_list,'-ob', label='Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAFYCAYAAAC/NO6RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt0VOW9//HPnpkMQyABEpPUnCLa\nHiOCCEUEzQVECFZ+tge0KKTgclWtVG2hgty0tYpyEbGA5SjHS2WhUDAVpVQB0VDARCyGhahYFGtF\nQZhouOVCMjP798eYcEsghNmzJ3ver7VmkexkZn+fmTCfeZ5n72cbpmmaAgAAjuKyuwAAABB5BDwA\nAA5EwAMA4EAEPAAADkTAAwDgQAQ8AAAO5LG7gEjy+w9F9PE6dEhUeXllRB8zFtFOZ6GdzkI7nSXS\n7UxLS2r0Z/TgT8HjcdtdQlTQTmehnc5CO50lmu0k4AEAcCACHgAAByLgAQBwIAIeAAAHIuABAHAg\nAh4AAAci4AEAcCACHgAAB7JsJbtNmzZpzJgxuvDCCyVJWVlZuu222zRhwgQFg0GlpaVp1qxZ8nq9\nWrFihRYuXCiXy6Ubb7xRw4YNU21trSZNmqTdu3fL7XZr+vTp6tixo1XlHmf5co/mzPFqxw4pKytR\nY8fWaOjQQFT2DQBAJFi6VG3v3r01b968+u8nT56sgoICXXvttXr88cdVWFioIUOGaP78+SosLFRC\nQoJ+9rOfKT8/X0VFRUpOTtbs2bO1ceNGzZ49W3PmzLGyXEnhcL/jjtb132/f7v7u+ypCHgDQYkR1\niH7Tpk0aMGCAJKl///4qKSnR1q1b1a1bNyUlJcnn86lnz54qLS1VSUmJ8vPzJUnZ2dkqLS2NSo1z\n5ngb3D53bsPbAQCIRZb24D/99FONHj1aBw4c0N13362qqip5veGgTE1Nld/vV1lZmVJSUurvk5KS\nctJ2l8slwzBUU1NTf/+GdOiQeNbr/O7Y0dh29ykX9W/pnNy2Y9FOZ6GdzkI7I8uygD///PN19913\n69prr9WuXbt08803KxgM1v/cNM0G73em248ViSv0ZGUlavv2kz8kZGUF5fc780pHaWlJEb8SXyyi\nnc5CO52Fdjb/8Rpj2RB9RkaGBg8eLMMwdN555+mcc87RgQMHVF1dLUnau3ev0tPTlZ6errKysvr7\n7du3r3673++XJNXW1so0zVP23iNl7NiaBrePGdPwdgAAYpFlAb9ixQo9++yzkiS/369vvvlG119/\nvVavXi1JWrNmjfLy8tS9e3dt27ZNBw8eVEVFhUpLS9WrVy/l5ORo1apVkqSioiL16dPHqlKPM3Ro\nQAsWVOnCC8OjDUlJphYs4AA7AEDLYphNGftuhsOHD2v8+PE6ePCgamtrdffdd+viiy/WxIkTdeTI\nEWVmZmr69OlKSEjQqlWr9Oyzz8owDI0cOVI//elPFQwGdf/99+vzzz+X1+vVjBkzdO65555yn5Ee\n3rniiiSVlZn6178Oy+3gSxUzNOYstNNZaKezRHOI3rKAt0Ok/zgmT07Ss89Kb7xRoe7dQxF97FjC\nfyxnoZ3OQjudxRFz8E5w9dXhfzdscHD3HQDgSAT8KfTvH/5340ZLzyYEACDiCPhTOPdc6cILg3rn\nHbdqa+2uBgCApiPgTyM3N6jKSkNbtvBUAQBaDlLrNHJzw6fLMUwPAGhJCPjTyM4OB/zbb3OgHQCg\n5SDgTyM11VTXrkG9+65b3y3CBwBAzCPgmyA3N6gjRwxt3kwvHgDQMhDwTZCbG16mduNGAh4A0DIQ\n8E1w5ZVBuVwmAQ8AaDEI+CZITpZ69AiptNStw4ftrgYAgNMj4JsoJyegQMDQu+/SiwcAxD4CvomO\nng9PwAMAYh8B30S9eweVkGCy4A0AoEUg4JuoTRupZ8+g3n/fpQMH7K4GAIBTI+DPQG5uUKGQoZIS\nhukBALGNgD8DeXmsSw8AaBkI+DNw2WVB+XycDw8AiH0E/Blo1Uq6/PKgPvrIrbIyw+5yAABoFAF/\nhuqG6YuL6cUDAGIXAX+GcnJYlx4AEPsI+DPUo0dIbdowDw8AiG0E/BlKSAhffObTT936+mvm4QEA\nsYmAbwaG6QEAsY6Ab4aj58MT8ACA2ETAN0PXriG1b8+69ACA2EXAN4PbLV15ZUBffOHSf/7DPDwA\nIPYQ8M1UN0z/9tsM0wMAYg8B30x114ffsIFhegBA7CHgm+mii0I655yQ3n7bLdO0uxoAAI5HwDeT\nYYR78V9/7dLOnczDAwBiCwF/FhimBwDEKgL+LOTmhhe84UA7AECsIeDPwgUXmMrMDM/Dh0J2VwMA\nwFEE/Fmom4f/5huXtm/nqQQAxA5S6SwxTA8AiEUE/FnKyWFdegBA7CHgz1LHjqbOPz+k4mKPgkG7\nqwEAIIyAj4Dc3IAOHjS0bRtPJwAgNpBIEcD58ACAWEPARwDz8ACAWEPAR0BGhqmsrKA2bXKrpsbu\nagAAIOAjJjc3qMpKQ1u20IsHANiPgI+Qunl4hukBALGAgI+Q7OyADMNkwRsAQEywNOCrq6s1cOBA\nvfzyy9qzZ49GjRqlgoICjRkzRjXfTVavWLFCN9xwg4YNG6aXXnpJklRbW6tx48ZpxIgRGjlypHbt\n2mVlmRGRkiJ17RrSP//pVlWV3dUAAOKdpQH/5JNPql27dpKkefPmqaCgQIsXL1anTp1UWFioyspK\nzZ8/X88//7wWLVqkhQsXav/+/Vq5cqWSk5O1ZMkSjR49WrNnz7ayzIjJzQ3qyBFDmzfTiwcA2Muy\ngN+5c6c+/fRTXXXVVZKkTZs2acCAAZKk/v37q6SkRFu3blW3bt2UlJQkn8+nnj17qrS0VCUlJcrP\nz5ckZWdnq7S01KoyI4p16QEAscKygJ85c6YmTZpU/31VVZW8Xq8kKTU1VX6/X2VlZUpJSan/nZSU\nlJO2u1wuGYZRP6Qfy668Mii322TBGwCA7SxJoldeeUU9evRQx44dG/y5aZoR2X6iDh0S5fFEtvec\nlpZ0Br8r9eolvfeeW61bJ6lt24iWYqkzaWdLRjudhXY6C+2MLEsCft26ddq1a5fWrVunr7/+Wl6v\nV4mJiaqurpbP59PevXuVnp6u9PR0lZWV1d9v37596tGjh9LT0+X3+9W5c2fV1tbKNM363v+plJdX\nRrQdaWlJ8vsPndF9+vTxatOmVvr73yt19dUt4+ozzWlnS0Q7nYV2OgvtbP7jNcaSIfo5c+bor3/9\nq5YtW6Zhw4bpzjvvVHZ2tlavXi1JWrNmjfLy8tS9e3dt27ZNBw8eVEVFhUpLS9WrVy/l5ORo1apV\nkqSioiL16dPHijItwbr0AIBYELUU+vWvf62JEydq6dKlyszM1JAhQ5SQkKBx48bp1ltvlWEYuuuu\nu5SUlKTBgweruLhYI0aMkNfr1YwZM6JV5lnr3TuohASTBW8AALYyzKZOcLcAkR7eae5Qyk9/2lqb\nNrn1r38dVvv2ES3JEgyNOQvtdBba6Swtfog+3uXmBmWahkpKGKYHANiDgLdAXh7r0gMA7EXAW6Bn\nz6B8PubhAQD2IeAt0KpV+GC77dvd8vsNu8sBAMQhAt4idcP0xcX04gEA0UfAWyQnJ7wu/YYNBDwA\nIPoIeIv06BFS27am3n6bI+kBANFHwFvE4wlffGbnTpd272YeHgAQXQS8heqG6TmaHgAQbQS8heoO\ntGOYHgAQbQS8hbp2Dal9e1MbNrjlnAWBAQAtAQFvIZdLys4O6MsvXfrPf5iHBwBEDwFvMYbpAQB2\nIOAtdvT68BxoBwCIHgLeYllZIaWlhbRxI/PwAIDoIeAtZhjhXvy+fS59+ilPNwAgOkicKGCYHgAQ\nbQR8FLDgDQAg2gj4KLjgAlP/9V8hFRe7FQrZXQ0AIB4Q8FFQNw//7bcuffQRTzkAwHqkTZQwTA8A\niCYCPkrqDrRjwRsAQDQQ8FHy/e+buuCC8Dx8IGB3NQAApyPgoyg3N6BDhwy9/z5POwDAWiRNFNUN\n02/cyDA9AMBaBHwU5eTUBTwH2gEArEXAR1F6uqnOnYN69123amrsrgYA4GQEfJTl5ARVWWmotJRe\nPADAOgR8lB2dhyfgAQDWIeCjLDs7IMMwCXgAgKUI+Cjr0EG65JKQNm92q6rK7moAAE5FwNsgNzeo\nmhpD//wnvXgAgDUIeBvk5bEuPQDAWgS8Da64Iii322TBGwCAZQh4G7RtK/XoEdKWLS4dPmx3NQAA\nJyLgbZKXF1AwaOiddximBwBEHgFvk6PL1jJMDwCIPALeJpdfHpTXy/nwAABrEPA2SUyUevUKats2\nl8rL7a4GAOA0BLyNcnKCMk1DJSUM0wMAIouAt1FeHuvSAwCsQcDbqGfPoFq3Zh4eABB5BLyNvF6p\nd++gPv7YrX37DLvLAQA4CAFvs7ph+uJievEAgMgh4G2Wmxtel37DBgIeABA5lh2+XVVVpUmTJumb\nb77RkSNHdOedd6pz586aMGGCgsGg0tLSNGvWLHm9Xq1YsUILFy6Uy+XSjTfeqGHDhqm2tlaTJk3S\n7t275Xa7NX36dHXs2NGqcm1z6aUhtW1r6u23PZKO2F0OAMAhLOvBFxUV6ZJLLtELL7ygOXPmaMaM\nGZo3b54KCgq0ePFiderUSYWFhaqsrNT8+fP1/PPPa9GiRVq4cKH279+vlStXKjk5WUuWLNHo0aM1\ne/Zsq0q1lccjZWcH9dlnLn31FfPwAIDIsCzgBw8erNtvv12StGfPHmVkZGjTpk0aMGCAJKl///4q\nKSnR1q1b1a1bNyUlJcnn86lnz54qLS1VSUmJ8vPzJUnZ2dkqLS21qlTb1Q3TczQ9ACBSLJ+DHz58\nuMaPH68pU6aoqqpKXq9XkpSamiq/36+ysjKlpKTU/35KSspJ210ulwzDUE1NjdXl2qJuXfrwMD0A\nAGfP8kT5y1/+ou3bt+vee++VaZr124/9+lhnuv1YHTokyuOJbC84LS0poo/XkKuuklJSpOLiBJ1z\nToIMG0bqo9HOWEA7nYV2OgvtjCzLAv6DDz5Qamqqzj33XF188cUKBoNq06aNqqur5fP5tHfvXqWn\npys9PV1lZWX199u3b5969Oih9PR0+f1+de7cWbW1tTJNs77335jy8sqItiEtLUl+/6GIPmZjOnVq\nrS1bPEpIMJWVFdLYsTUaOjQQlX1Hs512op3OQjudhXY2//EaY9kQ/ebNm/Xcc89JksrKylRZWans\n7GytXr1akrRmzRrl5eWpe/fu2rZtmw4ePKiKigqVlpaqV69eysnJ0apVqySFD9jr06ePVaXabvly\nj7ZsCX/WCgYNbd/u1h13tNby5QzZAwCax7IEGT58uO677z4VFBSourpav//973XJJZdo4sSJWrp0\nqTIzMzVkyBAlJCRo3LhxuvXWW2UYhu666y4lJSVp8ODBKi4u1ogRI+T1ejVjxgyrSrXdnDkNj0zM\nneuNWi8eAOAshtmUye0WItLDO9EaMjr33LYKBk+eePd4TO3efdjy/TM05iy001lop7M4YogeTZeV\nFTqj7QAAnA4BHwPGjm349L8xY5x5WiAAwHoEfAwYOjSgBQuq1LlzUJIpn8/UggVVzL8DAJqNgI8R\nQ4cGtH59pfr1C6q62tAVVwTtLgkA0IIR8DEmPz/ca1+7llPkAADNR8DHmLqAf+MN1qUHADQfAR9j\nLrjA1IUXBrV+vUfV1XZXAwBoqQj4GDRwYFCVlYaKi+nFAwCah4CPQYMGhYfp16xhHh4A0DwEfAzq\n3Tuo5GRTa9d65Jx1BgEA0UTAx6CEBKl//4C++MKlf/2LlwgAcOZIjxhVdzQ9w/QAgOYg4GPUgAFB\nGYaptWs50A4AcOYI+BiVmmrqsstCevddt8rL7a4GANDSEPAxbNCggEIhQ2+9xTA9AODMnHHA19TU\naM+ePVbUghMMHFi3qh0BDwA4M01KjgULFigxMVE/+9nPdMMNN6hNmzbKycnR2LFjra4vrnXtGlJm\nZkhvveVRICB5yHkAQBM1qQdfVFSkkSNHatWqVerfv79eeukllZaWWl1b3DOM8NH0+/cb2ryZg+0A\nAE3XpID3eDwyDEPr16/XwIEDJUmhUMjSwhDGxWcAAM3RpIBPSkrSL3/5S+3cuVM/+tGPVFRUJMMw\nrK4NknJzg/L5TObhAQBnpEmpMXv2bBUXF6tnz56SpFatWmnmzJmWFoawxEQpLy+oN97w6IsvDJ13\nHmvXAgBOr0k9+G+//VYdOnRQSkqKli1bppUrV6qqqsrq2vAdjqYHAJypJgX85MmTlZCQoI8++kgv\nvfSSrrnmGj388MNW14bvHJ2HJ+ABAE3TpIA3DEOXXnqp3njjDf385z9Xv379ZHKZs6j5/vdNdekS\n1Ntvu1VRYXc1AICWoEkBX1lZqffff1+rV69W3759VVNTo4MHD1pdG46Rnx/QkSOGNmzgaHoAwOk1\nKeB/8Ytf6He/+51uuukmpaSk6IknntB1111ndW04BsP0AIAz0aS0GDx4sAYPHqz9+/frwIEDuuee\nezhNLsouuyyklJSQ3njDI9M8Ip5+AMCpNKkH/95772ngwIG69tprNWjQIF177bXatm2b1bXhGG63\ndPXVQX39tUsffMA1ggAAp9akpHj88cf1v//7vyopKdGmTZv0+OOPa8aMGVbXhhMMGhQepl+zhmF6\nAMCpNSngXS6XsrKy6r/v0qWL3G4O9oq2/v0DcrtNrV1LwAMATq3JAb969WodPnxYhw8f1muvvUbA\n26BdO6lPn6BKS13y+5mEBwA0rkkB/+CDD2rZsmW6+uqrNWDAAL3yyit66KGHrK4NDcjPD8g0Db35\nJh+wAACNO+VYb0FBQf3R8qZp6r//+78lSYcPH9akSZP04osvWl8hjpOfH9SDD4ZPlxs+PGB3OQCA\nGHXKgB87dmy06kATXXhhSJ06hVRU5FFNjeT12l0RACAWnTLge/fuHa060ESGET6a/umnvdq0ya28\nvKDdJQEAYhAnVLdAdVeX43Q5AEBjCPgWKDs7qMREk2VrAQCNIuBboFatpKuuCuizz1zauZPT5QAA\nJyPgW6j8/PDcO714AEBDCPgWqm4enoAHADSEgG+hMjJMde8eVEmJW4cO2V0NACDWEPAtWH5+QIGA\noXXr6MUDAI5HwLdgXF0OANAYAr4Fu/TSkNLSQnrzTbdCIburAQDEEgK+BXO5wsP0ZWUubdnCSwkA\nOIpUaOE4XQ4A0BBLU+HRRx/Ve++9p0AgoDvuuEPdunXThAkTFAwGlZaWplmzZsnr9WrFihVauHCh\nXC6XbrzxRg0bNky1tbWaNGmSdu/eLbfbrenTp6tjx45Wltsi9esXUEJCeFW7SZNq7C4HABAjLOvB\nv/POO/rkk0+0dOlSPfPMM5o2bZrmzZungoICLV68WJ06dVJhYaEqKys1f/58Pf/881q0aJEWLlyo\n/fv3a+XKlUpOTtaSJUs0evRozZ4926pSW7S2bcNL127b5taePaxqBwAIsyzgL7/8cs2dO1eSlJyc\nrKqqKm3atEkDBgyQJPXv318lJSXaunWrunXrpqSkJPl8PvXs2VOlpaUqKSlRfn6+JCk7O1ulpaVW\nldri1R1Nv3Ytw/QAgDDLEsHtdisxMVGSVFhYqL59+2rjxo3yfncB89TUVPn9fpWVlSklJaX+fikp\nKSdtd7lcMgxDNTU19fdvSIcOifJ43BFtR1paUkQfzwo33STdd5/0j3/4dM89vmY9RktoZyTQTmeh\nnc5COyPL8i7f2rVrVVhYqOeee06DBg2q326aZoO/f6bbj1VeXtm8IhuRlpYkvz/2l4lLTpYuvDBR\na9e6tGvXYfnOMONbSjvPFu10FtrpLLSz+Y/XGEuPot+wYYOeeuopPf3000pKSlJiYqKqq6slSXv3\n7lV6errS09NVVlZWf599+/bVb/f7/ZKk2tpamaZ5yt57vBs4MKjKSkPFxZEdwQAAtEyWBfyhQ4f0\n6KOPasGCBWrfvr2k8Fz66tWrJUlr1qxRXl6eunfvrm3btungwYOqqKhQaWmpevXqpZycHK1atUqS\nVFRUpD59+lhVqiOwqh0A4FiWpcFrr72m8vJyjR07tn7bjBkzdP/992vp0qXKzMzUkCFDlJCQoHHj\nxunWW2+VYRi66667lJSUpMGDB6u4uFgjRoyQ1+vVjBkzrCrVEXr3Dio5OXy63PTpR2RwQD0AxDXD\nbMrkdgsR6fmbljYndPvtPr36aoLWr69Q585NX7u2pbWzuWins9BOZ6GdzX+8xrCSnYPk5zNMDwAI\nI+AdZMCAoAzD1Nq1HGgHAPGOgHeQ1FRTl10W0rvvulVebnc1AAA7EfAOM2hQQKGQobfeYpgeAOIZ\nAe8wdfPwXF0OAOIbAe8wXbqElJkZ0ltveRQI2F0NAMAuBLzDGEa4F79/v6HNmznYDgDiFQHvQEeH\n6Ql4AIhXBLwD5eYG5fOZzMMDQBwj4B0oMVHKywvq44/d+uIL1qwFgHhEwDvUwIEcTQ8A8YyAdyhO\nlwOA+EbAO9T3v2+qS5eg3n7brYoKu6sBAEQbAe9g+fkBHTliaMMGjqYHgHhDwDsYw/QAEL8IeAe7\n7LKQUlJCeuMNj0zT7moAANFEwDuY2y1dfXVQX3/t0gcf8FIDQDzhXd/hBg0KD9OvWcMwPQDEEwLe\n4fr3D8jtNrV2LQEPAPGEgHe4du2kPn2CKi11ad8+VrUDgHhBwMeB/PyATNPQW29xuhwAxAsCPg7k\n5wclcbocAMQTAj4OXHhhSJ06hVRU5FFNjd3VAACigYCPA4YRPpr+8GFDmzYxTA8A8YCAjxN1V5fj\ndDkAiA8EfJzIzg4qMdFkHh4A4gQBHydatZKuuiqgzz5zaedOTpcDAKcj4OMIR9MDQPwg4ONI3Tw8\nAQ8AzkfAx5GMDFM9egRVUuLWoUN2VwMAsBIBH2cGDgwoEDC0bh29eABwMgI+znB1OQCIDwR8nLn0\n0pDS0kJ68023QiG7qwEAWIWAjzMuV/jiM2VlLm3ZwssPAE7FO3wc4nQ5AHA+Aj4O9esXUEICq9oB\ngJMR8HGobdvw0rXbtrm1Zw+r2gGAExHwcaruaPq1a+nFA4ATEfBx6uiqdlw+FgCciICPUxdcYOrC\nC4Nav96j6mq7qwEARBoBH8fOP99UZaWhNm2kfv0StXw5w/UA4BQEfJxavtxTfxR9KCRt3+7WHXe0\nJuQBwCEI+Dg1Z463we1z5za8HQDQshDwcWrHjoZf+sa2AwBaFt7N41RWVsML0Te2HQDQslga8Dt2\n7NDAgQP1wgsvSJL27NmjUaNGqaCgQGPGjFFNTY0kacWKFbrhhhs0bNgwvfTSS5Kk2tpajRs3TiNG\njNDIkSO1a9cuK0uNO2PH1jS4ffTohrcDAFoWywK+srJSU6dO1ZVXXlm/bd68eSooKNDixYvVqVMn\nFRYWqrKyUvPnz9fzzz+vRYsWaeHChdq/f79Wrlyp5ORkLVmyRKNHj9bs2bOtKjUuDR0a0IIFVerS\nJSiPR0pNDffcGaIHAGew7N3c6/Xq6aefVnp6ev22TZs2acCAAZKk/v37q6SkRFu3blW3bt2UlJQk\nn8+nnj17qrS0VCUlJcrPz5ckZWdnq7S01KpS49bQoQGtW1ep2lrpvfcqdN55IT35pFfbthHyANDS\nWfZO7vF45PP5jttWVVUlrzd8lHZqaqr8fr/KysqUkpJS/zspKSknbXe5XDIMo35IH5GXmCg99li1\ngkFD99zjUyBgd0UAgLNh20nPpmlGZPuxOnRIlMcT2aVX09KSIvp4sSotLUnDhkmjRkmLFrm1ZEmS\n7rnH7qoiL55ez3hAO52FdkZWVAM+MTFR1dXV8vl82rt3r9LT05Wenq6ysrL639m3b5969Oih9PR0\n+f1+de7cWbW1tTJNs77335jy8sqI1puWliS//1BEHzMWHdvOKVMM/f3vifrd7wz161eh8847/Qer\nliIeX08no53OQjub/3iNiepka3Z2tlavXi1JWrNmjfLy8tS9e3dt27ZNBw8eVEVFhUpLS9WrVy/l\n5ORo1apVkqSioiL16dMnmqXGrdRUUw89dESVlYYmTPCpCQMnAIAYZFkP/oMPPtDMmTP11VdfyePx\naPXq1Xrsscc0adIkLV26VJmZmRoyZIgSEhI0btw43XrrrTIMQ3fddZeSkpI0ePBgFRcXa8SIEfJ6\nvZoxY4ZVpeIEw4YF9NJLAb31lkcvv+zRDTcwIQ8ALY1hNmVyu4WI9PBOPA8Zff65oX792qhNG1Mb\nN1bomOMgW6x4fj2diHY6C+1s/uM1hvOh0KDzzzd1771HVFbm0h/+4Dv9HQAAMYWAR6NGj65Vt25B\n/eUvCVq/PrJnJwAArEXAo1Eej/T449VyuUyNH+9TVZXdFQEAmoqAxyl17x7SHXfU6vPPXZo9m0vJ\nAkBLQcDjtCZMOKLzzgtp/nyvPviAPxkAaAl4t8ZptWkjPfpoeBnbceN8CgbtrggAcDoEPJrk6quD\nuuGGWm3Z4tazzybYXQ4A4DQIeDTZQw8dUYcOpqZNa6Vduwy7ywEAnAIBjyZLSzP14IPVqqw0NHEi\ny9gCQCwj4HFGbropoL59A1q71qNXX7XtYoQAgNMg4HFGDEOaNataPp+pKVNaqbzc7ooAAA0h4HHG\nLrjA1PjxNSorc+nBB1vZXQ4AoAEEPJrlV7+qUdeuQS1e7NXGjSxjCwCxhoBHsyQkHF3Gdtw4lrEF\ngFhDwKPZfvSjkG6/vVb//rdLf/wjy9gCQCwh4HFWJk48oo4dQ/rTn7z68EP+nAAgVvCOjLPStq00\nc2a1AgFD48ezjC0AxAoCHmdt4MCghg6t1XvvufXnP7OMLQDEAgIeETF16hG1b2/qkUda6auvWMYW\nAOxGwCMi0tPDy9hWVLCMLQDEAgIeETN8eEC5uQGtWePR3/7GMrYAYCcCHhFjGNJjj1WrVStTkye3\n0v79dlcEAPGLgEdE/eAH4WVs/X6XHnqIZWwBwC4EPCLuzjtrdPHFQb3wglfFxSxjCwB2IOARcXXL\n2BpGeBnb6mq7KwKA+EPAwxKXXRbSbbfVaudOl+bMYRlbAIg2Ah6WmTz5iP7rv0KaN8+r7dv5UwOA\naOJdF5Zp21Z69NHwMrbjxvn0ivKvAAAQYElEQVQUCtldEQDEDwIelsrPD+p//qdWmzezjC0ARBMB\nD8s9/PARtWsXXsZ2926WsQWAaCDgYbmMDFN/+MMRHT5saNKkVixjCwBRQMAjKgoKapWdHdCqVQm6\n7LI2OvfcturXL1HLl7OkLQBYgYBHVBiG9OMfByRJX37pUjBoaPt2t+64ozUhDwAWIOARNUuWNHyQ\n3dy5nCcPAJFGwCNqduxo+M9t+3aXXnvNo6qqKBcEAA5GwCNqsrIaPhHeNA3dcktrXXxxW91+u08r\nVnh0+HCUiwMAhyHgETVjx9Y0uH3y5Gr95jdHlJFh6tVXE3Tbba3VpUtb3XKLT3/9q0eHDkW5UABw\nAI5uQtQMHRqQVKW5c73ascOlrKyQxoyp+W67dN99NfrwQ5dWrvTob3/z6LXXEvTaawnyek1ddVVQ\n111Xqx//OKD27e1tBwC0BAQ8omro0EB9oJ/IMKRLLgnpkktqNGlSjf71L5f+9rdw2K9ZE755PKb6\n9g3quusCuvbagFJTOakeABpCwCNmXXRRSBddVKPx42u0c6ehlSsT9Le/efTWW+Hbvfeays4O6ic/\nCWjw4IDS0wl7AKjDHDxahB/+0NSYMTVau7ZS//znYT3wQLV69AhpwwaPJkzwqVu3Nvqf/2mtZ55J\n0J49LIcLAAQ8WpxOnUzddVetXn+9Ulu2HNbDD1erd++g3nnHrSlTfOreva0GD07Uk08maNcuQ8uX\ne9SvX6I8HrF6HoC4YZimc1YG9/sje7h1WlpSxB8zFjmlnXv3Gvr73z1audKj4mK3QqHGe/JPPVWl\n669v+FiAls4pr+fp0E5noZ3Nf7zG0JWBY2RkmPrFL2r1i1/Uyu839PrrHj3wQCtVVJwc9L/6lU9T\np5o655wTbyGdc46ptLTw7ZxzTKWmmvKe4WJ7y5d7NGfO0bMFxo6tafTgQgCwAgEPR0pLM3XzzbWa\nOLFVgz83TcntDq+ut3Xr6efs27U7/gNA3YeAY/+t+3lRkUejR7euv2/dmvtSFSEPIGoIeDhaVlZI\n27e7T9repUtI69ZVSpIqKqSyMkN+v6GyMkNlZa7v/jVO2G7o3/8+9dB/WMOzXlOmtNLnn7vUrp2p\ndu1MtW9vKjnZVPv2UnJyeJvP1/y2Hh01kLKyEqMyasBIhXXseD3hLDE9Bz9t2jRt3bpVhmFoypQp\nuvTSS0/5+8zBN4+T27l8uee73vPxFixoXm86GJTKy43jPgCc+EHg9dc9kpp3JL/PVxf6ppKTdcyH\ngPAHgGM/ENRta9fO1IYNbt1zT+Ta2RSRfm7PZL/h4HMrKyvoyA8y9j+30fvAFg+v5/H7jGw7TzUH\nH7MB/+677+rZZ5/VggULtHPnTk2ZMkVLly495X0I+OZxejuXL/d8t3pe+D/WsavnWaFfv8QGRw0u\nuCCoGTOO6MAB45ibtH+/oYMHjfp/j90eDJ7dKX8JCaa+/31Tbrcpt1sn3Vwu1f8s/HX45vFILpfZ\nwO8e/f2VKz0qLz/5RJy0tJBuvbVWHk/4dz0effe16rfVfX10u3nc7zR236Iit373u5OHOaZPr9ag\nQQHVvZuZphr8+uSfGae8j2lKb73l1tSpJ+9z4sRq5eUFFQqFHyMYlEKhxm6GgsHw49Vtq/v9um3B\noFH/sz/+0auvvz75uf3e90L69a9rZBjhhaHq1H1dt/3E70/+2jxuuySVlrr1/PMnH2zyq1/VKCcn\n8N3fxNHXx+U6+podfW2Pvm5H/46Ovr7H31965ZXof5Cx48OTlftskQE/d+5cZWZmatiwYZKkH//4\nxyosLFTbtm0bvQ8B3zy0M7Ii9Z/ZNMPTB8eG//79OuEDQvi2bJlHptnQhwFTGRlmfZgEAkb918Fg\n3Y11A2AXUw2Ndrlc4RGs8IcS87gPJy7X8R9k6m5126WGth99jM8/d6mm5uR9+nymLroo1ODju1zm\nSftpbP/Hfx2+38aNHh06dPI+u3QJ1k8VNleLPIq+rKxMXbt2rf8+JSVFfr//lAHfoUOiPJ6Te05n\n41RPnpPQzsj55S+l5GRp+nTpo4+kLl2kyZOl4cNPDv1I+egjadu2k7dfeqnRpIMIjw38QODY8G/8\n9pOfSJ98cvJj/eAH0oIF4cc53a1uf029LVhwfG+8jmFII0eevvd6+p7tyV/Pn9/wPl0uaeLE8L91\nt7qRjrP9fsIE6YsvTt5np07S7NkNj04cO+rQ2M9OdZ/bbw//HTTUzhkzjv/baOj1a87P169v+G8z\nFDLUsWPdCIdxXJ11Ix4nbmts+4nbahq+5pWqqw198on7uPsce9+GnpuztWOH29L3pJgN+BM1ZaCh\nvPzsPgmdiJ6ts0SznQMGhG/H8vut29/ddzc8anDXXVXy+89uCLBuCPZE48c3vM+JE6vUvbs1Q53/\n+EfD0x8XXxzU7NmR/f9f5803G95n585B/fa31uzzvvsafm6nTKlS377WPLcXXdR4O2+5xZp2Njad\n1aVLUG++Gf19NqU33VDwn/i1dPz2665L1I4dJ+8zKysov9+6HnzMrmSXnp6usrKy+u/37duntLQ0\nGysCYtfQoQEtWFClLl2C8njCb1ZWH5B1/D7NqOyzsUsOjxnTSLeshe7TjtczXp7bs92nYRw9viAh\nQWrVSvL5pNatpTZtpLZtw7fkZKldO6l9e2ncuOi3U4rhOfjS0lI98cQT+vOf/6wPP/xQDz/8sJYs\nWXLK+zAH3zy001mc3s5oHzR5/D5Pvsyx1aL5etrRznh5Pa1qZ4s8yE6SHnvsMW3evFmGYeiBBx5Q\n586dT/n7BHzz0E5noZ3OQjudhaVqvzN+/Hi7SwAAoEWK2Tl4AADQfAQ8AAAORMADAOBABDwAAA5E\nwAMA4EAEPAAADkTAAwDgQAQ8AAAOFNMr2QEAgOahBw8AgAMR8AAAOBABDwCAAxHwAAA4EAEPAIAD\nEfAAADgQAd+IadOm6aabbtLw4cP1/vvv212OZR599FHddNNNuuGGG7RmzRq7y7FMdXW1Bg4cqJdf\nftnuUiy1YsUK/fSnP9X111+vdevW2V2OJSoqKnT33Xdr1KhRGj58uDZs2GB3SRG1Y8cODRw4UC+8\n8IIkac+ePRo1apQKCgo0ZswY1dTU2FxhZDTUzltuuUUjR47ULbfcIr/fb3OFkXFiO+ts2LBBF110\nkaX7JuAb8O677+o///mPli5dqkceeUSPPPKI3SVZ4p133tEnn3yipUuX6plnntG0adPsLskyTz75\npNq1a2d3GZYqLy/X/PnztXjxYj311FN688037S7JEsuXL9cFF1ygRYsWae7cuY76/1lZWampU6fq\nyiuvrN82b948FRQUaPHixerUqZMKCwttrDAyGmrnnDlzdOONN+qFF15Qfn6+/vznP9tYYWQ01E5J\nOnLkiP7v//5PaWlplu6fgG9ASUmJBg4cKEn64Q9/qAMHDujw4cM2VxV5l19+uebOnStJSk5OVlVV\nlYLBoM1VRd7OnTv16aef6qqrrrK7FEuVlJToyiuvVNu2bZWenq6pU6faXZIlOnTooP3790uSDh48\nqA4dOthcUeR4vV49/fTTSk9Pr9+2adMmDRgwQJLUv39/lZSU2FVexDTUzgceeEDXXHONpONf45as\noXZK0lNPPaWCggJ5vV5L90/AN6CsrOy4N42UlBTHDBcdy+12KzExUZJUWFiovn37yu1221xV5M2c\nOVOTJk2yuwzLffnll6qurtbo0aNVUFDgiCBoyP/7f/9Pu3fvVn5+vkaOHKmJEyfaXVLEeDwe+Xy+\n47ZVVVXVB0Fqaqoj3osaamdiYqLcbreCwaAWL16sn/zkJzZVFzkNtfPf//63Pv74Y1177bXW79/y\nPTiA01fzXbt2rQoLC/Xcc8/ZXUrEvfLKK+rRo4c6duxodylRsX//fv3pT3/S7t27dfPNN6uoqEiG\nYdhdVkS9+uqryszM1LPPPquPP/5YU6ZMcfyxFXWc/l4UDAY1YcIEXXHFFScNazvF9OnTdf/990dl\nXwR8A9LT01VWVlb//b59+yyfK7HLhg0b9NRTT+mZZ55RUlKS3eVE3Lp167Rr1y6tW7dOX3/9tbxe\nr773ve8pOzvb7tIiLjU1VT/60Y/k8Xh03nnnqU2bNvr222+Vmppqd2kRVVpaqtzcXElS586dtW/f\nPgWDQUeOPknhnm11dbV8Pp/27t170nCvk0yePFmdOnXS3XffbXcplti7d68+++wzjR8/XlI4W0aO\nHHnSAXiRwhB9A3JycrR69WpJ0ocffqj09HS1bdvW5qoi79ChQ3r00Ue1YMECtW/f3u5yLDFnzhz9\n9a9/1bJlyzRs2DDdeeedjgx3ScrNzdU777yjUCik8vJyVVZWOmp+uk6nTp20detWSdJXX32lNm3a\nODbcJSk7O7v+/WjNmjXKy8uzuSJrrFixQgkJCfrNb35jdymWycjI0Nq1a7Vs2TItW7ZM6enploW7\nRA++QT179lTXrl01fPhwGYahBx54wO6SLPHaa6+pvLxcY8eOrd82c+ZMZWZm2lgVmisjI0PXXHON\nbrzxRknS/fffL5fLeZ/hb7rpJk2ZMkUjR45UIBDQH/7wB7tLipgPPvhAM2fO1FdffSWPx6PVq1fr\nscce06RJk7R06VJlZmZqyJAhdpd51hpq5zfffKNWrVpp1KhRksIHOLf017ahdj7xxBNR61BxuVgA\nABzIeR/vAQAAAQ8AgBMR8AAAOBABDwCAAxHwAAA4EAEPwHIvv/xy/eIeAKKDgAcAwIFY6AZAvUWL\nFun1119XMBjUD37wA912222644471LdvX3388ceSpD/+8Y/KyMjQunXrNH/+fPl8PrVu3VpTp05V\nRkaGtm7dqmnTpikhIUHt2rXTzJkzJUmHDx/W+PHjtXPnTmVmZupPf/qT49bJB2IJPXgAkqT3339f\nb7zxhl588UUtXbpUSUlJKi4u1q5du3T99ddr8eLF6t27t5577jlVVVXp/vvv1xNPPKFFixapb9++\nmjNnjiTp3nvv1dSpU/XCCy/o8ssv1z/+8Q9J0qeffqqpU6fq5Zdf1ieffKIPP/zQzuYCjkcPHoCk\n8HXHv/jiC918882SpMrKSu3du1ft27fXJZdcIim8jPPChQv1+eefKzU1Vd/73vckSb1799Zf/vIX\nffvttzp48KCysrIkSbfccouk8Bx8t27d1Lp1a0nhZXUPHToU5RYC8YWAByBJ8nq9uvrqq/X73/++\nftuXX36p66+/vv570zRlGMZJQ+vHbm9s9esTLwjDKtmAtRiiByAp3Dtfv369KioqJEkvvvii/H6/\nDhw4oI8++khS+FKtF110kc4//3x988032r17tySppKRE3bt3V4cOHdS+fXu9//77kqTnnntOL774\noj0NAuIcPXgAkqRu3brp5z//uUaNGqVWrVopPT1dffr0UUZGhl5++WXNmDFDpmnq8ccfl8/n0yOP\nPKLf/va38nq9SkxM1COPPCJJmjVrlqZNmyaPx6OkpCTNmjVLa9assbl1QPzhanIAGvXll1+qoKBA\n69evt7sUAGeIIXoAAByIHjwAAA5EDx4AAAci4AEAcCACHgAAByLgAQBwIAIeAAAHIuABAHCg/w9V\n/UhIt0pUJgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rS0Ap9WJh3Ui",
        "colab_type": "code",
        "outputId": "722bedcb-fe0e-47fb-e3a4-0d72c1e28b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "cell_type": "code",
      "source": [
        "epoch_cap = list(range(8))\n",
        "plt.figure()\n",
        "plt.plot(epoch_cap,train_acc_list,'-ob', label='train')\n",
        "plt.plot(epoch_cap,val_acc_list,'-og', label='validation')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxvx/9YPaTsAm6KwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5b50hj6lI8Pl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predictTest(model, testing_data, sample_only=False):\n",
        "    image_list = copy.deepcopy(test_dataset.image_list)\n",
        "    predictions = []\n",
        "    jpg = []\n",
        "    lenTest = len(testing_data) * 1.0\n",
        "    progress_print = 3\n",
        "    for index, (image, label, imageName) in enumerate(testing_data):\n",
        "          image = image.to(device)\n",
        "          predicted = model(image)\n",
        "          top5Pred, top5PredIndices = torch.topk(predicted, 5)\n",
        "          for p in range(len(top5PredIndices)):\n",
        "              currPred = top5PredIndices[p]\n",
        "              currPred.cpu()\n",
        "              relabel_whaleid = []\n",
        "              for i in currPred:          \n",
        "                  relabel_whaleid.append(weight_df.loc[int(i),'Id'])\n",
        "              jpg.append(imageName[p])\n",
        "              predictions.append(' '.join(relabel_whaleid))  \n",
        "          if index % progress_print == 0:\n",
        "            print(f'{index / lenTest * 100}%')\n",
        "          if sample_only:\n",
        "            break;\n",
        "    \n",
        "    whale_predictions = pd.DataFrame({'Image':jpg,'Id':predictions})\n",
        "    return whale_predictions          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvYSUOCoPwFh",
        "colab_type": "code",
        "outputId": "1535aa7e-785f-4177-a78e-a62b262a0d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!cd /content/drive/My\\ Drive/CS\\ 175\\ Final\\ Project/data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: /content/drive/My Drive/CS 175 Final Project/data: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Djj3VjPgdX4u",
        "colab_type": "code",
        "outputId": "1670eeb6-591b-406b-d0db-4928d71d908b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1564
        }
      },
      "cell_type": "code",
      "source": [
        "final_test_predictions = predictTest(final_model, full_test_generator, False)\n",
        "final_test_predictions = final_test_predictions[final_test_predictions.columns[::-1]]\n",
        "print(final_test_predictions)\n",
        "final_test_predictions.to_csv('rn_50submission.csv', index=False)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0%\n",
            "3.75%\n",
            "7.5%\n",
            "11.25%\n",
            "15.0%\n",
            "18.75%\n",
            "22.5%\n",
            "26.25%\n",
            "30.0%\n",
            "33.75%\n",
            "37.5%\n",
            "41.25%\n",
            "45.0%\n",
            "48.75%\n",
            "52.5%\n",
            "56.25%\n",
            "60.0%\n",
            "63.74999999999999%\n",
            "67.5%\n",
            "71.25%\n",
            "75.0%\n",
            "78.75%\n",
            "82.5%\n",
            "86.25%\n",
            "90.0%\n",
            "93.75%\n",
            "97.5%\n",
            "              Image                                                 Id\n",
            "0     02ef5fee0.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "1     329746ad4.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "2     23892fdc3.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "3     18d0bfd1b.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "4     013cb8d04.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "5     8473b9c07.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "6     4167bc057.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7     c75d27e8c.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "8     4ac21b9c5.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "9     4e4110a8c.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "10    bf42cdb63.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "11    16f390578.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "12    69f6cd44f.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "13    c5876a853.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "14    908472d1c.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "15    51b4747d8.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "16    0e453962b.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "17    ecc365c91.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "18    d08fd7c11.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "19    f256dfa87.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "20    e00b4294f.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "21    4a63614dc.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "22    7654768c8.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "23    4c8b7aa93.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "24    7a6042cfe.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "25    e1060f178.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "26    e1aa5a2bb.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "27    f7a8cd22d.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "28    83033395f.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "29    cf0229cbb.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "...             ...                                                ...\n",
            "7930  82043d011.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7931  918ac7175.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7932  8670262ea.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7933  9df4b4875.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7934  c34d2211c.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7935  332ab8314.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7936  0f71bd2d3.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7937  7d76b0a52.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7938  585ff7fb8.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7939  de74478c6.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7940  82d75a6bf.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7941  6d87370db.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7942  802330ff6.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7943  566fb8d5c.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7944  317181820.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7945  61f45212e.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7946  b0148424e.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7947  e37181714.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7948  149ec0b2b.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7949  758ce9a31.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7950  33971e6d5.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7951  ce284ed1a.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7952  3b8e16e13.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7953  b09e0f3f8.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7954  5deee355e.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7955  016bbca6e.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7956  236848dba.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7957  bfe7ec5ab.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7958  3babecf06.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "7959  40a6dd1b4.jpg  new_whale w_9b5109b w_9c506f6 w_700ebb4 w_0369a5c\n",
            "\n",
            "[7960 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}